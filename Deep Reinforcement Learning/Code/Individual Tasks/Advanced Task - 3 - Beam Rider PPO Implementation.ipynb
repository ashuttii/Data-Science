{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Advanced Task - 3 - Beam Rider PPO Implementation.ipynb","provenance":[{"file_id":"10dVrRrii0Ol-NGVzegNFamGZKKMABdOs","timestamp":1650804879572}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Proximal Policy Optimization Implementation"],"metadata":{"id":"l6lSR3ndCOvz"}},{"cell_type":"markdown","source":["Installing library dependencies"],"metadata":{"id":"giEefQLDnb9m"}},{"cell_type":"code","source":["!pip install gym\n","!pip install pyglet==1.2.4\n","import urllib.request\n","urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n","\n","!pip install unrar\n","!unrar x Roms.rar\n","\n","# !python -m atari_py.import_roms rars\n","!pip install \"gym[atari,accept-rom-license]\"\n","!pip install atari-py\n","!apt install xvfb -y\n","!pip install pyvirtualdisplay\n","!pip install piglet\n","!apt-get install python-opengl -y\n","!apt install xvfb -y\n","!python -m atari_py.import_roms ROMS\n","\n","!pip install -U \"ray[tune]\"  # installs Ray + dependencies for Ray Tune\n","!pip install -U \"ray[rllib]\"  # installs Ray + dependencies for Ray RLlib\n","!pip install -U \"ray[serve]\"\n","!pip install 'ray[rllib]'==1.6\n","!apt-get install -y xvfb x11-utils\n","# !pip install pyvirtualdisplay==0.2.*\n","!pip install tensorboard\n","%matplotlib inline"],"metadata":{"id":"rvNw8MbQu8WH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jj6dBw-fwDb0","executionInfo":{"status":"ok","timestamp":1650751306172,"user_tz":-60,"elapsed":17671,"user":{"displayName":"Radhu Palliyana","userId":"06047451316246614289"}},"outputId":"8fbd34f1-3a5a-48fc-d24d-e4a104a65418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Loading OpenAI Gym Beam Rider environment:**\n","\n","Space Invaders environment is loaded and tried to understand the environment by looking into the observation space and action space"],"metadata":{"id":"blMZz5-SntpQ"}},{"cell_type":"code","source":["import gym\n","import random"],"metadata":{"id":"OB7EkoO4IO2y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyvirtualdisplay import Display    #for virtual display\n","display = Display(visible=0, size=(1400, 900))\n","_ = display.start()"],"metadata":{"id":"KP_wck_tIQnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env = gym.make('BeamRider-v0')"],"metadata":{"id":"EYObEez2IXKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random, math\n","import numpy as np\n","\n","from ray.rllib.env.env_context import EnvContext\n","from ray.rllib.models import ModelCatalog\n","\n","from gym.spaces import Discrete,Box\n","\n","import ray\n","import ray.rllib.agents.dqn as dqn\n","from ray.tune.logger import pretty_print\n","\n","from ray import tune\n","from ray.rllib.agents.ppo import PPOTrainer\n","\n","from ray.tune.schedulers import ASHAScheduler"],"metadata":{"id":"goekFMxHIZxc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ray.rllib.agents import ppo"],"metadata":{"id":"_rAJnQ-Fm4ZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load tensorboard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"PHw9T4UMnW8X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\n","    \"use_critic\" : True,\n","    \"kl_coeff\" : 0.2, # initial coefficient for KL divergence\n","    \"train_batch_size\" :4000, \n","    \"env\" : \"SpaceInvaders-v0\",\n","    \"framework\" : \"torch\",\n","    \"model\" : {\n","        \"fcnet_hiddens\" : [32,32], # number of hidden layers used\n","        \"fcnet_activation\" : \"linear\", # activation function used\n","              },\n","    \"sgd_minibatch_size\" : 256, # minibatch size within each epoch\n","    \"num_sgd_iter\" : 30, # number of epochs to execute per train batch\n","    \"lr\" : 5e-5, #stepsize of SGD\n","    \"vf_loss_coeff\" : 1.0, # coefficient of the value function loss\n","    \"clip_param\" : 0.3, #PPO clip parameter\n","    \"vf_clip_param\" : 10,\n","    \"kl_target\" : 0.01,\n","    \"batch_mode\" : \"truncate_episodes\"\n","\n","        }\n","\n","stop = {\"training_iteration\": 20}\n","\n","ray.shutdown()\n","\n","ray.init(   \n","    num_cpus =8,\n","    num_gpus = 1,\n","    include_dashboard = False,\n","    ignore_reinit_error =True,\n","    log_to_driver = False,    \n",")\n","# Asha scheduler is used implement early stopping\n","asha_scheduler = ASHAScheduler(\n","    #time_attr='training_iteration',\n","    metric='episode_reward_mean',\n","    mode='max',\n","    \n","    )\n","\n","trainer = ppo.PPOTrainer(config = config, env = 'BeamRider-v0' )\n","\n","avg_rewards_ppo = []\n","for i in range(20):\n","  result = trainer.train()\n","  print(result['episode_reward_mean'])\n","  avg_rewards_ppo.append(result['episode_reward_mean'])\n","\n","  if i % 5 == 0:\n","      checkpoint= trainer.save()\n","      print(\"checkpoint save at\", checkpoint)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7O9ev-Pr_mg7","outputId":"3850d2c0-e57d-4bc1-e656-765be00599bc","executionInfo":{"status":"ok","timestamp":1650758996172,"user_tz":-60,"elapsed":7665983,"user":{"displayName":"Radhu Palliyana","userId":"06047451316246614289"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n","  warnings.warn(warning_message)\n","2022-04-23 22:02:13,216\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n","2022-04-23 22:02:13,219\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","2022-04-23 22:02:23,306\tINFO trainable.py:109 -- Trainable.setup took 10.092 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n","2022-04-23 22:02:23,310\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"]},{"output_type":"stream","name":"stdout","text":["nan\n","checkpoint save at /root/ray_results/PPO_BeamRider-v0_2022-04-23_22-02-13dzjndf7k/checkpoint_000001/checkpoint-1\n","396.0\n","330.0\n","334.4\n","313.5\n","312.4\n","checkpoint save at /root/ray_results/PPO_BeamRider-v0_2022-04-23_22-02-13dzjndf7k/checkpoint_000006/checkpoint-6\n","297.0\n","323.7142857142857\n","327.25\n","331.29411764705884\n","332.2\n","checkpoint save at /root/ray_results/PPO_BeamRider-v0_2022-04-23_22-02-13dzjndf7k/checkpoint_000011/checkpoint-11\n","322.0\n","330.0\n","335.0769230769231\n","326.2068965517241\n","321.2\n","checkpoint save at /root/ray_results/PPO_BeamRider-v0_2022-04-23_22-02-13dzjndf7k/checkpoint_000016/checkpoint-16\n","324.0\n","324.8235294117647\n","339.77777777777777\n","340.42105263157896\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=((10,8)))\n","#plt.xlabel = ('episodes')\n","#plt.ylabel = ('average rewards')\n","#plt.title = ('average rewards accumulated for episodes')\n","plt.plot(avg_rewards_dqn,'b.',alpha = .4)\n","plt.show()"],"metadata":{"id":"6Lhh8f7_GvZy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650714956306,"user_tz":-60,"elapsed":224,"user":{"displayName":"Radhu Palliyana","userId":"06047451316246614289"}},"outputId":"48d5d883-f1e5-4582-b697-336a58507293"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<Figure size 720x576 with 1 Axes>\n"]}]},{"cell_type":"markdown","source":["The code reference : \n","Lab 8 and 9\n","\n","https://github.com/ray-project/ray/blob/master/rllib/agents/trainer.py\n","https://usermanual.wiki/m/d8984f2e85323f04b1b3e4597da5fc177cf7b2e13344b957445d9aa729dfc985.pdf"],"metadata":{"id":"Ka0bTVJ5nRGq"}}]}