{"cells":[{"cell_type":"markdown","source":["## **Emotion Recognision - Jupyter Notebook**\n","\n","This code is written in Jupyter notebook to render Webcam video. cv2_imshow() does not render video insted output frames of images.\n","\n","**cv2.imshow() render video in Jupyter Notebook**\n","\n","**RUN THIS CODE ONLY IN JUPYTER NOTEBOOK**\n","\n","If any error occurs reinsall open-cv and run the code again"],"metadata":{"id":"a2G0Qni8Ri-g"},"id":"a2G0Qni8Ri-g"},{"cell_type":"code","execution_count":null,"id":"42d64e48","metadata":{"id":"42d64e48","outputId":"e81d9096-b4f5-4608-939d-261fcba3912b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python==4.5.5.64 in /Users/ashuttii/opt/anaconda3/lib/python3.9/site-packages (4.5.5.64)\r\n","Requirement already satisfied: numpy>=1.17.3 in /Users/ashuttii/opt/anaconda3/lib/python3.9/site-packages (from opencv-python==4.5.5.64) (1.20.3)\r\n"]}],"source":["!pip install opencv-python==4.5.5.64"]},{"cell_type":"code","execution_count":null,"id":"54ba39b5","metadata":{"id":"54ba39b5","outputId":"07759616-a153-4e32-eda4-b943b770ea48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python==4.5.5.64 in /Users/ashuttii/opt/anaconda3/lib/python3.9/site-packages (4.5.5.64)\r\n","Requirement already satisfied: numpy>=1.14.5 in /Users/ashuttii/opt/anaconda3/lib/python3.9/site-packages (from opencv-python==4.5.5.64) (1.20.3)\r\n"]}],"source":["!pip install opencv-python==4.5.5.64"]},{"cell_type":"code","execution_count":null,"id":"cede90e2","metadata":{"id":"cede90e2"},"outputs":[],"source":["import torch\n","path = './CNN_model.pth'\n","model = torch.load(path, map_location=\"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"0b7c98e0","metadata":{"id":"0b7c98e0","outputId":"c8fc7fe5-01dd-4450-b1e4-a5e3f69e8e9e"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","model_ret = models.resnet18(pretrained=True)\n","num_ftrs = model_ret.fc.in_features\n","# Here the size of each output sample is set to 2.\n","# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n","model_ret.fc = nn.Linear(num_ftrs, 7)\n","model_ret.load_state_dict(model)"]},{"cell_type":"code","execution_count":null,"id":"714d530c","metadata":{"id":"714d530c"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from PIL import Image\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import copy"]},{"cell_type":"code","execution_count":null,"id":"c489d92f","metadata":{"id":"c489d92f"},"outputs":[],"source":["face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n","\n","webcam = True\n","cap = cv2.VideoCapture(0) if webcam else cv2.VideoCapture(video_path)"]},{"cell_type":"code","execution_count":null,"id":"45ec796c","metadata":{"id":"45ec796c"},"outputs":[],"source":["face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n","\n","data_means = [0.485, 0.456, 0.406]\n","data_stds = [0.229, 0.224, 0.225]\n","transform = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(data_means, data_stds)\n","    ])"]},{"cell_type":"code","execution_count":null,"id":"66e0ddb4","metadata":{"id":"66e0ddb4"},"outputs":[],"source":["#BELOW CODE IS TO RENDER VIDEO "]},{"cell_type":"code","execution_count":null,"id":"941262e7","metadata":{"id":"941262e7"},"outputs":[],"source":["frameNum = 0\n","while True:\n","    frameNum +=1\n","    ret, img = cap.read()\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n","\n","    for (x,y,w,h) in faces:\n","        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n","        roi_gray = gray[y:y+h, x:x+w]\n","        roi_color = img[y:y+h, x:x+w]\n","        converted_image = Image.fromarray(cv2.cvtColor(roi_color, cv2.COLOR_BGR2RGB))\n","        trans_frame = transform(converted_image)\n","    outputs = model_ret(trans_frame.unsqueeze(0))\n","    _, preds = torch.max(outputs.data, 1)\n","    emo = {0: \"Surprise\", 1: \"Fear\", 2: \"Disgust\", 3: \"Happiness\", 4: \"Sadness\", 5: \"Anger\", 6: \"Neutral\"}\n","    cv2.putText(img, emo[preds.item()], (200,200), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0),3)\n","                                        \n","    cv2.imshow('img',img)\n","    k = cv2.waitKey(30) & 0xff\n","    \n","    #To run continously comment the if statment below\n","    if frameNum == 20:\n","        break\n","\n","cap.release()\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"ba71c5f9","metadata":{"id":"ba71c5f9"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"JupyterNotebook_EmotionRecognition_VideoRender.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}